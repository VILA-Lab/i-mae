{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzv_hKibotyt"
      },
      "source": [
        "## i-MAE: Visualization Demo\n",
        "This is a visualization demo of our pre-trained i-MAE model only reconstructing the subordinate image. The notebook is based off of: https://github.com/facebookresearch/mae.\n",
        "\n",
        "### Prepare\n",
        "Check environment. Install packages if in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oP1s191otyx",
        "outputId": "6e6a847f-9fc3-40cf-8e5d-34e951b172d0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# check whether run in Colab\n",
        "if 'google.colab' in sys.modules:\n",
        "    print('Running in Colab.')\n",
        "    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab\n",
        "    !git clone https://github.com/vision-learning-acceleration-lab/i-mae.git\n",
        "    sys.path.append('./i-mae')\n",
        "import os\n",
        "import requests\n",
        "import torchvision\n",
        "import timm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import models_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkH5QTzmotyz"
      },
      "source": [
        "### Define utils\n",
        "define the utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpdFfmImoty0"
      },
      "outputs": [],
      "source": [
        "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
        "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "def show_image(image, title=''):\n",
        "    # image is [H, W, 3]\n",
        "    assert image.shape[2] == 3\n",
        "    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.axis('off')\n",
        "    return\n",
        "\n",
        "def prepare_model(chkpt_dir, arch='mae_vit_small_patch8_dec1928b'):\n",
        "    # build model\n",
        "    model = getattr(models_mae, arch)()\n",
        "    # load model\n",
        "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
        "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
        "    print(msg)\n",
        "    return model\n",
        "\n",
        "def run_one_image(img, model, mask_ratio):\n",
        "    x = torch.tensor(img)\n",
        "\n",
        "    # make it a batch-like\n",
        "    new_x = []\n",
        "    for i in x:\n",
        "        i = i.unsqueeze(dim=0)\n",
        "        i = torch.einsum('nhwc->nchw', i)\n",
        "        i = i.float()\n",
        "        new_x.append(i)\n",
        "    # run MAE\n",
        "    loss, y, mask = model(new_x, weak_idx=0, mask_ratio=mask_ratio)\n",
        "    y = model.unpatchify(y[0])\n",
        "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
        "    # visualize the mask\n",
        "    mask = mask.detach()\n",
        "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *3)  # (N, H*W, p*p*3)\n",
        "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
        "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
        "    \n",
        "    new_x[0] = torch.einsum('nchw->nhwc', new_x[0])\n",
        "    new_x[1] = torch.einsum('nchw->nhwc', new_x[1])\n",
        "    new_x[2] = torch.einsum('nchw->nhwc', new_x[2])\n",
        "    # masked image\n",
        "    im_masked = new_x[0] * (1 - mask) + ((1-torch.Tensor(imagenet_mean))/torch.Tensor(imagenet_std)) * mask\n",
        "\n",
        "    # MAE reconstruction pasted with visible patches\n",
        "    im_paste = new_x[1] * (1 - mask) + y * mask\n",
        "\n",
        "    # make the plt figure larger\n",
        "    plt.rcParams['figure.figsize'] = [24, 24]\n",
        "\n",
        "    plt.subplot(1, 6, 1)\n",
        "    show_image(x[0], \"mixture input\")\n",
        "\n",
        "    plt.subplot(1, 6, 2)\n",
        "    show_image(im_masked[0], \"input + mask\")\n",
        "\n",
        "    plt.subplot(1, 6, 3)\n",
        "    show_image(y[0], \"subordinate reconstruction\")\n",
        "\n",
        "    plt.subplot(1, 6, 4)\n",
        "    show_image(im_paste[0], \"reconstruction + visible\")\n",
        "\n",
        "    plt.subplot(1, 6, 5)\n",
        "    show_image(x[1], \"subordinate target\")\n",
        "\n",
        "    plt.subplot(1, 6, 6)\n",
        "    show_image(x[2], \"dominant target\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVgH13MVoty1"
      },
      "source": [
        "### Load an image\n",
        "load an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1P7Z79Boty1"
      },
      "outputs": [],
      "source": [
        "img_url_1 = 'https://user-images.githubusercontent.com/11435359/147738734-196fd92f-9260-48d5-ba7e-bf103d29364d.jpg' # fox, from ILSVRC2012_val_00046145\n",
        "img_url_2 = 'https://user-images.githubusercontent.com/11435359/147743081-0428eecf-89e5-4e07-8da5-a30fd73cc0ba.jpg' # cucumber, from ILSVRC2012_val_00047851\n",
        "\n",
        "im_1 = Image.open(requests.get(img_url_1, stream=True).raw)\n",
        "im_1 = im_1.resize((224, 224))\n",
        "im_1 = np.array(im_1) / 255.\n",
        "im_2 = Image.open(requests.get(img_url_2, stream=True).raw)\n",
        "im_2 = im_2.resize((224, 224))\n",
        "im_2 = np.array(im_2) / 255.\n",
        "\n",
        "im_1 = im_1 - imagenet_mean\n",
        "im_1 = im_1 / imagenet_std\n",
        "im_2 = im_2 - imagenet_mean\n",
        "im_2 = im_2 / imagenet_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyA8qJUfoty2"
      },
      "source": [
        "### Load a pre-trained MAE model\n",
        "\n",
        "This is an i-MAE trained model with pixels as targets for visualization (ViT-base, training mask ratio=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "rTHocKAxoty3",
        "outputId": "40ccd5f0-c55e-4d75-b56f-628c97abd5c8"
      },
      "outputs": [],
      "source": [
        "# download checkpoint if not exist\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1rpXg8r15cpAtTK4QkaNY725KZ9jTJpBL' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1rpXg8r15cpAtTK4QkaNY725KZ9jTJpBL\" -O vit-base-sub-imae.pth && rm -rf /tmp/cookies.txt\n",
        "\n",
        "chkpt_dir = 'vit-base-sub-imae.pth'\n",
        "model_mae = prepare_model(chkpt_dir, 'mae_vit_base_patch16')\n",
        "print('Model loaded.')\n",
        "\n",
        "mask_ratio = 0.5\n",
        "mix_ratio = 0.3\n",
        "\n",
        "torch.manual_seed(4)\n",
        "print('MAE with pixel reconstruction mix ratio:{}, maskratio:{}'.format(mix_ratio, mask_ratio))\n",
        "\n",
        "img_comb = mix_ratio * im_1  + (1-mix_ratio) *im_2\n",
        "imgs = [img_comb, im_1, im_2]\n",
        "run_one_image(imgs, model_mae,  mask_ratio=mask_ratio)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('mae')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c0145ff9cbd1ef7b77d8c22f684ed3bad2b6fd712525ed47742528a6ae1b427c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
